# Paper-List


- [Must_Read](#Must_Read)
- [Visual_Language_Model](Visual_Language_Model)
- [Diffusion](#Diffusion)
- [Anomaly Detection](#Anomaly_Detection)
   * [Error Reasoning](#Error_Reasoning)
   * [Anomaly_Detection_with_Diffusion_Model](#Anomaly_Detection_with_Diffusion_Model)
   * [Video_Anomaly_Detection](#Video_Anomaly_Detection)
   * [Procedural_Error_Detection](#Procedural_Error_Detection)
- [Video Understanding](#Video_Understanding)
  * [Online Action Detection](#Online_Action_Detection)
  * [Temporal Action Localization](#Temporal_Action_Localization)
  * [Temporal Action Segmentation](#Temporal_Action_Segmentation)
  * [Temporal Procedural Planning](#Temporal_Procedural_Planning)
- [Procedural Learning Dataset](#Procedural_Learning_Dataset)
  * [Without Error](#Without_Error)
  * [With Error](#With_Error)
- [Object Localization_Detection](#Object_Localization_Detection)
- [Open-set Action Recognition](#Open-set_Action_Recognition)
- [Out-of-distribution Detection](#Out-of-distribution_Detection)
- [Fine-grained_Action_Dataset](#Fine-grained_Action_Dataset)
- [Other interesting papers](#Other_Interesting_Papers)

## New papers
- [(Arxiv25) StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant](https://arxiv.org/pdf/2505.05467)
- [(CVPR25) VideoGLaMM : A Large Multimodal Model for Pixel-Level Visual Grounding in Videos](https://openaccess.thecvf.com/content/CVPR2025/papers/Munasinghe_VideoGLaMM__A_Large_Multimodal_Model_for_Pixel-Level_Visual_Grounding_CVPR_2025_paper.pdf)
- [(CVPR25) PHGC: Procedural Heterogeneous Graph Completion for Natural Language Task Verification in Egocentric Videos](https://openaccess.thecvf.com/content/CVPR2025/papers/Jiang_PHGC_Procedural_Heterogeneous_Graph_Completion_for_Natural_Language_Task_Verification_CVPR_2025_paper.pdf)

## Must_Read
- [(Arxiv25) Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos](https://arxiv.org/pdf/2511.20525)
- [(Arxiv25) Vision-Based Mistake Analysis in Procedural Activities: A Review of Advances and Challenges](https://www.arxiv.org/abs/2510.19292)

## Vision_Language_Model
- [(ECCV24) LongVLM: Efficient Long Video Understanding via Large Language Models](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/04936.pdf)
- [(EMNLP23) Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?](https://aclanthology.org/2023.findings-emnlp.824.pdf)
- [(NIPS23) Visual Instruction Tuning](https://arxiv.org/pdf/2304.08485)
- [(ICCV23) EgoVLPv2: Egocentric Video-Language Pre-training with Fusion in the Backbone](https://arxiv.org/pdf/2307.05463)
- [(CVPR23) Learning Video Representations from Large Language Models](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Learning_Video_Representations_From_Large_Language_Models_CVPR_2023_paper.pdf)

## Diffusion
- [(CVPR24) GenHowTo: Learning to Generate Actions and State Transformations from Instructional Videos](https://arxiv.org/pdf/2312.07322.pdf)
- [(CVPR23) Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.pdf)
- [(CVPR22) High-Resolution Image Synthesis with Latent Diffusion Models](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)


## Anomaly_Detection
- [(CVPR25) AA-CLIP: Enhancing Zero-Shot Anomaly Detection via Anomaly-Aware CLIP](https://arxiv.org/pdf/2503.06661)
### Error_Reasoning
- [(CVPR25) VITED : Video Temporal Evidence Distillation](https://arxiv.org/pdf/2503.12855)
- [(CVPR25) VERA: Explainable Video Anomaly Detection via Verbalized Learning of Vision-Language Models](https://arxiv.org/pdf/2412.01095)
- [(CVPR25) Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models](https://arxiv.org/pdf/2502.07601)
- [(NAACL25) ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding](https://arxiv.org/pdf/2410.22211)
- [(NAACL25) LogicAD: Explainable Anomaly Detection via VLM-based Text Feature Extraction](https://arxiv.org/pdf/2501.01767)
- [(Arxiv24) Explainable Procedural Mistake Detection](https://arxiv.org/pdf/2412.11927)
- [(NIPS24) Holmes-VAD: Towards Unbiased and Explainable Video Anomaly Detection via Multi-modal LLM](https://arxiv.org/pdf/2406.12235)
### Anomaly_Detection_with_Diffusion_Model
- [(ICCV23) Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.pdf)
- [(ICIP23) EXPLORING DIFFUSION MODELS FOR UNSUPERVISED VIDEO ANOMALY DETECTION](https://arxiv.org/pdf/2304.05841.pdf) 
- [(Arxiv23) Time Series Anomaly Detection using Diffusion-based Models](https://arxiv.org/pdf/2311.01452.pdf)
- [(MICCAI22) Diffusion Models for Medical Anomaly Detection](https://arxiv.org/pdf/2203.04306.pdf)
### Video_Anomaly_Detection
- [(ICASSP25) SUVAD: Semantic Understanding Based Video Anomaly Detection Using MLLM](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10888431&tag=1)
- [(CVPR24) Harnessing Large Language Models for Training-free Video Anomaly Detection](https://openaccess.thecvf.com/content/CVPR2024/papers/Zanella_Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection_CVPR_2024_paper.pdf)
- [(ICCV23) Feature Prediction Diffusion Model for Video Anomaly Detection](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.pdf)
- [(CVPR23) Unbiased Multiple Instance Learning for Weakly Supervised Video Anomaly Detection](https://openaccess.thecvf.com/content/CVPR2023/papers/Lv_Unbiased_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_Detection_CVPR_2023_paper.pdf)
- [(CVPR23) Generating Anomalies for Video Anomaly Detection with Prompt-based Feature Mapping](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Generating_Anomalies_for_Video_Anomaly_Detection_With_Prompt-Based_Feature_Mapping_CVPR_2023_paper.pdf)
- [(CVPR23) Prompt-Guided Zero-Shot Anomaly Action Recognition using Pretrained Deep Skeleton Features](https://openaccess.thecvf.com/content/CVPR2023/papers/Sato_Prompt-Guided_Zero-Shot_Anomaly_Action_Recognition_Using_Pretrained_Deep_Skeleton_Features_CVPR_2023_paper.pdf)
- [(ECCV22) Self-Supervised Sparse Representation for Video Anomaly Detection](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136730727.pdf)
- [(CVPR22) Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection](https://openaccess.thecvf.com/content/CVPR2022/papers/Ristea_Self-Supervised_Predictive_Convolutional_Attentive_Block_for_Anomaly_Detection_CVPR_2022_paper.pdf)
- [(ICCV21) A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_A_Hybrid_Video_Anomaly_Detection_Framework_via_Memory-Augmented_Flow_Reconstruction_ICCV_2021_paper.pdf)
- [(TPAMI21) A Background-Agnostic Framework with Adversarial Training for Abnormal Event Detection in Video](https://arxiv.org/pdf/2008.12328.pdf)
### Procedural_Error_Detection
- [(CVPR25) Gazing Into Missteps: Leveraging Eye-Gaze for Unsupervised Mistake Detection in Egocentric Videos of Skilled Human Activities](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://openaccess.thecvf.com/content/CVPR2025/papers/Mazzamuto_Gazing_Into_Missteps_Leveraging_Eye-Gaze_for_Unsupervised_Mistake_Detection_in_CVPR_2025_paper.pdf)
- [(CVPR24) PREGO: online mistake detection in PRocedural EGOcentric videos](https://arxiv.org/pdf/2404.01933.pdf)
- [(NIPS24) Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos](https://arxiv.org/pdf/2406.01486)

## Video_Understanding
- [CVPR25 Omnia de EgoTempo: Benchmarking Temporal Understanding of Multi-Modal LLMs in Egocentric Videos](https://openaccess.thecvf.com/content/CVPR2025/papers/Plizzari_Omnia_de_EgoTempo_Benchmarking_Temporal_Understanding_of_Multi-Modal_LLMs_in_CVPR_2025_paper.pdf)
- (Frame selection)[(CVPR25) VIDEOTREE: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_VideoTree_Adaptive_Tree-based_Video_Representation_for_LLM_Reasoning_on_Long_CVPR_2025_paper.pdf)
- (Frame selection)[(CVPR25) BOLT: Boost Large Vision-Language Model Without Training for Long-form Video Understanding](https://arxiv.org/pdf/2503.21483)
- [(CVPR25) Progress-Aware Video Frame Captioning](https://arxiv.org/pdf/2412.02071)
- [(CVPR24) TimeChat: A Time-sensitive Multimodal Large Language Model for Long Video Understanding](https://openaccess.thecvf.com/content/CVPR2024/papers/Ren_TimeChat_A_Time-sensitive_Multimodal_Large_Language_Model_for_Long_Video_CVPR_2024_paper.pdf)
- [(CVPR24) Action Scene Graphs for Long-Form Understanding of Egocentric Videos](https://openaccess.thecvf.com/content/CVPR2024/papers/Rodin_Action_Scene_Graphs_for_Long-Form_Understanding_of_Egocentric_Videos_CVPR_2024_paper.pdf)
### Online_Action_Detection
- [(ICCV23) MiniROAD: Minimal RNN Framework for Online Action Detection](https://openaccess.thecvf.com/content/ICCV2023/papers/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.pdf)
- [(CVPR25) Context-Enhanced Memory-Refined Transformer for Online Action Detection](https://arxiv.org/pdf/2503.18359)
### Temporal_Action_Localization
- (VLM, training-free)[(IEEE Access25) Open-Vocabulary Action Localization with Iterative Visual Prompting](https://arxiv.org/abs/2408.17422)
- [(???) TemporalMaxer: Maximize Temporal Context with only Max Pooling for Temporal Action Localization](https://arxiv.org/pdf/2303.09055v1.pdf)
- [(ECCV22) ActionFormer: Localizing Moments of Actions with Transformers](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640485.pdf)
- [(ICCV23) Learning from Noisy Pseudo Labels for Semi-Supervised Temporal Action Localization](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Learning_from_Noisy_Pseudo_Labels_for_Semi-Supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf)
- [(ICCV23) DDG-Net: Discriminability-Driven Graph Network for Weakly-supervised Temporal Action Localization](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_DDG-Net_Discriminability-Driven_Graph_Network_for_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf)
- [(ICCV23) Action Sensitivity Learning for Temporal Action Localization](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Action_Sensitivity_Learning_for_Temporal_Action_Localization_ICCV_2023_paper.pdf)
- [(ICCV23) Revisiting Foreground and Background Separation in Weakly-supervised Temporal Action Localization: A Clustering-based Approach](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Revisiting_Foreground_and_Background_Separation_in_Weakly-supervised_Temporal_Action_Localization_ICCV_2023_paper.pdf)
- [(ECCV22) Weakly-Supervised Temporal Action Detection for Fine-Grained Videos with Hierarchical Atomic Actions](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700562.pdf)

### Temporal_Action_Segmentation
- (VLM, online)[(ICCV25) Streaming VideoLLMs for Real-time Procedural Video Understanding](https://openaccess.thecvf.com/content/ICCV2025/papers/Chatterjee_Streaming_VideoLLMs_for_Real-Time_Procedural_Video_Understanding_ICCV_2025_paper.pdf)
- [(ICCV23) Diffusion Action Segmentation](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.pdf)
#### Unsupervised
- [(CVPR22) Unsupervised Action Segmentation by Joint Representation Learning and Online Clustering](https://openaccess.thecvf.com/content/CVPR2022/papers/Kumar_Unsupervised_Action_Segmentation_by_Joint_Representation_Learning_and_Online_Clustering_CVPR_2022_paper.pdf)
- [(ICCV19) Weakly Supervised Energy-Based Learning for Action Segmentation](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Weakly_Supervised_Energy-Based_Learning_for_Action_Segmentation_ICCV_2019_paper.pdf)
#### Weakly-supversied
- [(ECCV22) Dual-Evidential Learning for Weakly-supervised Temporal Action Localization](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640190.pdf)
- [(CVPR22) Weakly-Supervised Online Action Segmentation in Multi-View Instructional Videos](https://openaccess.thecvf.com/content/CVPR2022/papers/Ghoddoosian_Weakly-Supervised_Online_Action_Segmentation_in_Multi-View_Instructional_Videos_CVPR_2022_paper.pdf)
- [(ICCV19) Weakly Supervised Energy-Based Learning for Action Segmentation](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Weakly_Supervised_Energy-Based_Learning_for_Action_Segmentation_ICCV_2019_paper.pdf)


### Temporal_Procedural_Planning
- [(CVPR23) PDPP: Projected Diffusion for Procedure Planning in Instructional Videos](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_PDPPProjected_Diffusion_for_Procedure_Planning_in_Instructional_Videos_CVPR_2023_paper.pdf)

## Procedural_Learning_Dataset

### Without_Error

### With_Error
- [(ICML23) CaptainCook4D: A dataset for understanding errors in procedural activities](https://arxiv.org/pdf/2312.14556)
- [(???) IndustReal: A Dataset for Procedure Step Recognition Handling Execution Errors in Egocentric Videos in an Industrial-Like Setting](https://arxiv.org/pdf/2310.17323.pdf)
- [(NIPS23) Every Mistake Counts in Assemble](https://arxiv.org/pdf/2307.16453.pdf)
- [(CVPR23) HoloAssist: an Egocentric Human Interaction Dataset for Interactive AI Assistants in the Real World](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_HoloAssist_an_Egocentric_Human_Interaction_Dataset_for_Interactive_AI_Assistants_ICCV_2023_paper.pdf)
- [(CVPR22) Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities](https://openaccess.thecvf.com/content/CVPR2022/papers/Sener_Assembly101_A_Large-Scale_Multi-View_Video_Dataset_for_Understanding_Procedural_Activities_CVPR_2022_paper.pdf)


## Object_Localization
- [(Arxiv23) What, when, and where? - Self-Supervised Spatio-Temporal Grounding in Untrimmed Multi-Action Videos from Narrated Instructions](https://arxiv.org/pdf/2303.16990.pdf)
- [(ICCV23) Self-Supervised Object Detection from Egocentric Videos](https://openaccess.thecvf.com/content/ICCV2023/papers/Akiva_Self-Supervised_Object_Detection_from_Egocentric_Videos_ICCV_2023_paper.pdf)
- [(WACV23) TCAM: Temporal Class Activation Maps for Object Localization in Weakly-Labeled Unconstrained Videos](https://openaccess.thecvf.com/content/WACV2023/papers/Belharbi_TCAM_Temporal_Class_Activation_Maps_for_Object_Localization_in_Weakly-Labeled_WACV_2023_paper.pdf)


## Open-set_Action_Recognition
- [(NIPS24) Opening the Vocabulary of Egocentric Actions](https://arxiv.org/pdf/2308.11488)
- [(ICLR24) UNSUPERVISED OPEN-VOCABULARY ACTION RECOGNITION WITH AN AUTOREGRESSIVE MODEL](https://openreview.net/pdf?id=IryGDUHxDE)
- [(NIPS23) Opening the Vocabulary of Egocentric Actions](https://openreview.net/pdf?id=JzQ7QClAdF)
- [(CVPR23) Enlarging Instance-specific and Class-specific Information for Open-set Action Recognition](https://openaccess.thecvf.com/content/CVPR2023/papers/Cen_Enlarging_Instance-Specific_and_Class-Specific_Information_for_Open-Set_Action_Recognition_CVPR_2023_paper.pdf)
- [(CVPR23) Open Set Action Recognition via Multi-Label Evidential Learning](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Open_Set_Action_Recognition_via_Multi-Label_Evidential_Learning_CVPR_2023_paper.pdf)
- [(Arxiv22) Human Activity Recognition in an Open World](https://arxiv.org/pdf/2212.12141.pdf)
- [(ICCV21) Evidential Deep Learning for Open Set Action Recognition](https://openaccess.thecvf.com/content/ICCV2021/papers/Bao_Evidential_Deep_Learning_for_Open_Set_Action_Recognition_ICCV_2021_paper.pdf)

## Out-of-distribution_Detection
- [(WACV24) ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection](https://openaccess.thecvf.com/content/WACV2024/papers/Phan_ZEETAD_Adapting_Pretrained_Vision-Language_Model_for_Zero-Shot_End-to-End_Temporal_Action_WACV_2024_paper.pdf)
- [(CVPR24) Learning Transferable Negative Prompts for Out-of-Distribution Detection](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Learning_Transferable_Negative_Prompts_for_Out-of-Distribution_Detection_CVPR_2024_paper.pdf)
- [(CVPR24) Open-World Semantic Segmentation Including Class Similarity](https://openaccess.thecvf.com/content/CVPR2024/papers/Sodano_Open-World_Semantic_Segmentation_Including_Class_Similarity_CVPR_2024_paper.pdf)
- [(Arxiv23) DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization](https://arxiv.org/pdf/2308.02282.pdf)
- [(MICCAI23 Dual Conditioned Diffusion Models for Out-Of-Distribution Detection: Application to Fetal Ultrasound Videos)](https://arxiv.org/pdf/2311.00469.pdf)
- [(CVPR19) Out-of-Distribution Detection for Generalized Zero-Shot Action Recognition](https://openaccess.thecvf.com/content_CVPR_2019/papers/Mandal_Out-Of-Distribution_Detection_for_Generalized_Zero-Shot_Action_Recognition_CVPR_2019_paper.pdf)

## Fine-grained_Action_Dataset
- [(CVPR2024) FineSports: A Multi-person Hierarchical Sports Video Dataset for Fine-grained Action Understanding](https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_FineSports_A_Multi-person_Hierarchical_Sports_Video_Dataset_for_Fine-grained_Action_CVPR_2024_paper.pdf)
- [(CVPR2020) FineGym: A Hierarchical Video Dataset for Fine-grained Action Understanding](https://arxiv.org/pdf/2004.06704)



## Other_Interesting_Papers
- [(CVPR24) Describing Differences in Image Sets with Natural Language](https://openaccess.thecvf.com/content/CVPR2024/papers/Dunlap_Describing_Differences_in_Image_Sets_with_Natural_Language_CVPR_2024_paper.pdf)
- [(CVPR24) Step Differences in Instructional Video](https://openaccess.thecvf.com/content/CVPR2024/papers/Nagarajan_Step_Differences_in_Instructional_Video_CVPR_2024_paper.pdf)
- [(CVPR24) Learning Object State Changes in Videos: An Open-World Perspective](https://openaccess.thecvf.com/content/CVPR2024/papers/Xue_Learning_Object_State_Changes_in_Videos_An_Open-World_Perspective_CVPR_2024_paper.pdf)
- [(SCIA23) Evidential Deep Learning for Class-Incremental Semantic Segmentation](https://arxiv.org/pdf/2212.02863.pdf)
- [(Arxiv23) AVID: Any-Length Video Inpainting with Diffusion Model](https://arxiv.org/pdf/2312.03816.pdf)
- [(ICCV23) Learning to Ground Instructional Articles in Videos through Narrations](https://openaccess.thecvf.com/content/ICCV2023/papers/Mavroudi_Learning_to_Ground_Instructional_Articles_in_Videos_through_Narrations_ICCV_2023_paper.pdf)
